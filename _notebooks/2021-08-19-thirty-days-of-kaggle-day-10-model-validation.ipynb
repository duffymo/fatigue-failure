{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "% 30 Days of Kaggle - Day 10: (https://www.kaggle.com/dansbecker/underfitting-and-overfitting)[Over-Fitting and Under-Fitting].\n",
    "\n",
    "Now that I can create models I need to be able to evaluate their accuracy.\n",
    "\n",
    "I calculated mean absolute error in the last notebook using sklearn.\n",
    "\n",
    "MAE = \\frac{\\sum_0^N | predicted - actual |}{N}\n",
    "\n",
    "The lesson notes give a great explanation of under- and over-fitting:\n",
    "\n",
    "![Under-And-Over-Fitting](../images/30-days-of-kaggle/under-and-overfitting.png, 'Under-And-Over-Fitting')\n",
    "\n",
    "They use the example of housing data.   Decision tree depth is the variable to watch.  A binary tree of depth n will have 2^n leaf nodes. If n is too small we may be under-fitting.  If n is too large we eventually end up with one case in each leaf node.  There's a sweet spot that we have to find for training data.\n",
    "\n",
    "Use this utility method to compare MAE for different max leaf nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, predictions_val)\n",
    "    return mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These cells repeat the earlier calculations for the Melbourne housing data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "melbourne_file_path = '../datasets/kaggle/melbourne-house-prices/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea',\n",
    "                      'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data into train and test sets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's calculate MEA with differing values of max_leaf_nodes:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes:    5 \t\t Mean Absolute Error: 347380\n",
      "Max leaf nodes:   50 \t\t Mean Absolute Error: 258171\n",
      "Max leaf nodes:  500 \t\t Mean Absolute Error: 243495\n",
      "Max leaf nodes: 5000 \t\t Mean Absolute Error: 254983\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %4d \\t\\t Mean Absolute Error: %d\" %(max_leaf_nodes, my_mae))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercises: do the same thing with the Iowa housing model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 262,494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "iowa_file_path = '../datasets/kaggle/iowa-house-prices/train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "y = home_data.SalePrice\n",
    "feature_columns = ['Lot Area', 'Year Built', '1st Flr SF', '2nd Flr SF', 'Bedroom AbvGr', 'TotRms AbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes:    5 \t\t Mean Absolute Error: 347380\n",
      "Max leaf nodes:   25 \t\t Mean Absolute Error: 271044\n",
      "Max leaf nodes:   50 \t\t Mean Absolute Error: 258171\n",
      "Max leaf nodes:  100 \t\t Mean Absolute Error: 248734\n",
      "Max leaf nodes:  250 \t\t Mean Absolute Error: 247206\n",
      "Max leaf nodes:  500 \t\t Mean Absolute Error: 243495\n",
      "Max leaf nodes:  600 \t\t Mean Absolute Error: 243951\n",
      "Max leaf nodes:  700 \t\t Mean Absolute Error: 242954\n",
      "Max leaf nodes:  800 \t\t Mean Absolute Error: 244042\n",
      "Max leaf nodes:  900 \t\t Mean Absolute Error: 246292\n",
      "Max leaf nodes: 1000 \t\t Mean Absolute Error: 247345\n"
     ]
    }
   ],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500, 600, 700, 800, 900, 1000]\n",
    "for max_leaf_nodes in candidate_max_leaf_nodes:\n",
    "    mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %4d \\t\\t Mean Absolute Error: %d\" %(max_leaf_nodes, mae))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we know that we want 500 leaf nodes we can use all the data to create the final model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_leaf_nodes=500)\n"
     ]
    }
   ],
   "source": [
    "final_model = DecisionTreeRegressor(max_leaf_nodes=500)\n",
    "final_model.fit(X, y)\n",
    "print(final_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}